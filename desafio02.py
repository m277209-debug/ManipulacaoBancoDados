# -*- coding: utf-8 -*-
"""desafio02

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KAd7xGkjQdMVg6og2juh1SukYdt9vAC8
"""

# Importa a biblioteca pandas para manipulação de dados
import pandas as pd
# Importa a biblioteca matplotlib.pyplot para criação de gráficos
import matplotlib.pyplot as plt
# Importa a biblioteca seaborn para visualização de dados estatísticos
import seaborn as sns
# Importa a biblioteca numpy para operações numéricas
import numpy as np
# Importa a biblioteca os para operações do sistema operacional
import os
import zipfile # Importa a biblioteca zipfile para lidar com erros de arquivo zip

# Define a função getStats que processa um pedaço (chunk) dos dados
def getStats(chunk):
    # Lista das companhias aéreas de interesse
    airlines = ["AA", "DL", "UA", "US"]
    # Filtra o chunk para incluir apenas voos das companhias aéreas especificada
    chunk_filtered = chunk[chunk["AIRLINE"].isin(airlines)].copy()

    # Remove linhas onde os campos de interesse (YEAR, MONTH, DAY, AIRLINE, ARRIVAL_DELAY) têm valores ausentes
    chunk_filtered.dropna(subset=["YEAR", "MONTH", "DAY", "AIRLINE", "ARRIVAL_DELAY"], inplace=True)

    # Converte as colunas de data para tipo inteiro
    chunk_filtered["YEAR"] = chunk_filtered["YEAR"].astype(int)
    chunk_filtered["MONTH"] = chunk_filtered["MONTH"].astype(int)
    chunk_filtered["DAY"] = chunk_filtered["DAY"].astype(int)
    # Converte a coluna de atraso de chegada para tipo float
    chunk_filtered["ARRIVAL_DELAY"] = chunk_filtered["ARRIVAL_DELAY"].astype(float)

    # Agrupa os dados por ano, mês, dia e companhia aérea
    # Calcula o total de voos e o número de voos atrasados (atraso > 10 minutos) para cada grupo
    stats = chunk_filtered.groupby(["YEAR", "MONTH", "DAY", "AIRLINE"]).apply(lambda x: pd.Series({
        "total_flights": len(x),
        "delayed_flights": (x["ARRIVAL_DELAY"] > 10).sum()
    }), include_groups=False).reset_index()

    # Retorna as estatísticas calculadas para o chunk
    return stats

# Define a função computeStats que combina as estatísticas de todos os chunks
def computeStats(all_stats):
    # Agrupa as estatísticas combinadas por ano, mês, dia e companhia aérea
    # Soma o total de voos e os voos atrasados de todos os chunks
    combined_stats = all_stats.groupby(["YEAR", "MONTH", "DAY", "AIRLINE"]).agg({
        "total_flights": "sum",
        "delayed_flights": "sum"
    }).reset_index()

    # Calcula o percentual de voos atrasados
    combined_stats["Perc"] = combined_stats["delayed_flights"] / combined_stats["total_flights"]

    # Cria uma coluna 'Data' no formato AAAA-MM-DD a partir das colunas de ano, mês e dia
    combined_stats["Data"] = pd.to_datetime(combined_stats[["YEAR", "MONTH", "DAY"]])

    # Seleciona e renomeia as colunas finais conforme o requisito
    final_stats = combined_stats[["AIRLINE", "Data", "Perc"]].rename(columns={"AIRLINE": "Cia"})

    # Retorna as estatísticas finais
    return final_stats

# Define o tamanho do chunk para leitura do arquivo CSV (100.000 observações por vez)
chunk_size = 100000
# Inicializa uma lista para armazenar as estatísticas de cada chunk
all_chunks_stats = []

# Define as colunas de interesse para otimizar o uso de memória durante a leitura
columns_of_interest = [
    "YEAR", "MONTH", "DAY", "AIRLINE", "ARRIVAL_DELAY"
]

# Caminho do arquivo zip e o nome do arquivo CSV dentro do zip
arquivo_zip = "/flights.csv.zip"
arquivo_csv_dentro_zip = "flights.csv"
extracted_csv_path = "/content/flights.csv" # Caminho onde o CSV será extraído

# Verifica se o arquivo zip existe antes de tentar lê-lo
if not os.path.exists(arquivo_zip):
    print(f"ERRO: Arquivo zip não encontrado em {arquivo_zip}")
    print("Por favor, verifique se o caminho do arquivo zip está correto.")
else:
    try:
        # Extrai o arquivo CSV desejado do zip
        with zipfile.ZipFile(arquivo_zip, 'r') as zip_ref:
            if arquivo_csv_dentro_zip in zip_ref.namelist():
                zip_ref.extract(arquivo_csv_dentro_zip, "/content/")
                print(f"'{arquivo_csv_dentro_zip}' extracted successfully to {extracted_csv_path}")
            else:
                print(f"ERRO: '{arquivo_csv_dentro_zip}' not found in the zip file.")
                print(f"Files available in the zip: {zip_ref.namelist()}")
                extracted_csv_path = None # Define como None se a extração falhar

        if extracted_csv_path and os.path.exists(extracted_csv_path):
            # Loop para ler o arquivo flights.csv em chunks
            # usecols é usado para ler apenas as colunas necessárias, economizando memória
            for i, chunk in enumerate(pd.read_csv(extracted_csv_path, chunksize=chunk_size, usecols=columns_of_interest)):
                # Imprime o número do chunk que está sendo processado
                print(f"Processing chunk {i+1}...")
                # Chama a função getStats para processar o chunk atual
                chunk_stats = getStats(chunk)
                # Adiciona as estatísticas do chunk à lista
                all_chunks_stats.append(chunk_stats)

            # Verifica se há dados para processar
            if all_chunks_stats:
                # Concatena todas as estatísticas dos chunks em um único DataFrame
                full_stats_df = pd.concat(all_chunks_stats)
                # Chama a função computeStats para calcular as estatísticas finais
                final_results = computeStats(full_stats_df)
                # Imprime uma mensagem de conclusão
                print("Final results computed.")
                # Exibe as primeiras linhas dos resultados finais
                print(final_results.head())

                # Gera mapas de calor para cada companhia aérea
                for airline_code in final_results["Cia"].unique():
                    # Filtra os dados para a companhia aérea atual
                    airline_data = final_results[final_results["Cia"] == airline_code].copy()
                    # Extrai o dia do ano
                    airline_data["day_of_year"] = airline_data["Data"].dt.dayofyear
                    # Extrai a semana do ano (usando isocalendar para compatibilidade ISO)
                    airline_data["week_of_year"] = airline_data["Data"].dt.isocalendar().week.astype(int)
                    # Extrai o dia da semana (Monday=0, Sunday=6)
                    airline_data["day_of_week"] = airline_data["Data"].dt.dayofweek

                    # Cria uma tabela pivô para o heatmap
                    # As linhas representam os dias da semana e as colunas as semanas do ano, com os valores sendo o percentual de atraso
                    heatmap_data = airline_data.pivot_table(index="day_of_week", columns="week_of_year", values="Perc")

                    # Reordena os dias da semana para começar no domingo (6 no pandas, que será o primeiro)
                    # Mapeamento: 6 (Dom), 0 (Seg), 1 (Ter), 2 (Qua), 3 (Qui), 4 (Sex), 5 (Sab)
                    heatmap_data = heatmap_data.reindex([6, 0, 1, 2, 3, 4, 5])
                    # Renomeia os índices para os nomes dos dias da semana em português
                    heatmap_data.index = ["Domingo", "Segunda", "Terça", "Quarta", "Quinta", "Sexta", "Sábado"]

                    # Cria uma nova figura para o gráfico com um tamanho específico
                    plt.figure(figsize=(15, 8))
                    # Gera o heatmap usando seaborn
                    # cmap define o mapa de cores, linewidths e linecolor para as linhas da grade, cbar_kws para o rótulo da barra de cores
                    sns.heatmap(heatmap_data, cmap="RdYlGn_r", linewidths=.5, linecolor="lightgray", cbar_kws={"label": "Percentual de Atraso (%)"})
                    # Define o título do gráfico
                    plt.title(f"Percentual de Atrasos de Voo para {airline_code} em 2015", fontsize=16)
                    # Define o rótulo do eixo X
                    plt.xlabel("Semana do Ano", fontsize=12)
                    # Define o rótulo do eixo Y
                    plt.ylabel("Dia da Semana", fontsize=12)
                    # Garante que os rótulos do eixo Y não sejam rotacionados
                    plt.yticks(rotation=0)
                    # Ajusta o layout para evitar sobreposição de elementos
                    plt.tight_layout()
                    # Salva o gráfico como um arquivo PNG na pasta Documentos
                    # Obtém o caminho da pasta Documentos do usuário
                    documents_path = os.path.expanduser("~/Documents")
                    # Define o caminho completo para salvar o arquivo
                    save_path = os.path.join(documents_path, f"heatmap_{airline_code}.png")
                    # Salva o gráfico
                    plt.savefig(save_path)
                    # Fecha a figura para liberar memória
                    plt.close()
                    # Imprime uma mensagem informando onde o heatmap foi salvo
                    print(f"Heatmap for {airline_code} saved to {save_path}")
            # Se não houver dados para processar, imprime uma mensagem
            else:
                print("No data to process after filtering.")
        else:
            print("No data to process.")

    except zipfile.BadZipFile:
        print(f"ERRO: O arquivo em {arquivo_zip} não é um arquivo zip válido ou está corrompido.")
        print("Por favor, verifique a integridade do arquivo.")
    except Exception as e:
        print(f"Ocorreu um erro inesperado durante a leitura ou processamento do arquivo: {e}")